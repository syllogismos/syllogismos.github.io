
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>My Blog</title>
  <meta name="author" content="syllogismos">

  
  <meta name="description" content="Ghost is a minimalistic blogging platform that is very easy to setup. You can use it as your github user page using a tool called buster My current &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://syllogismos.github.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="My Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">My Blog</a></h1>
  
    <h2>My learnings and etc.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="syllogismos.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/15/ghost-blog-as-your-github-profile-page/">Ghost Blog as Your Github User Page</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-09-15T19:54:00+05:30'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>7:54 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Ghost is a minimalistic blogging platform that is very easy to setup. You can use it as your github user page using a tool called <a href="https://github.com/axitkhurana/buster">buster</a></p>

<p>My current github pages are setup using Octopress, both ghost and octopress has its advantages and disadvantages. Every time I&rsquo;m making a new post using octopress, I have to go to some online markdown editor to write my post. Where as Ghost has its inbuilt markdown editor where you can preview your changes as you type. That can be a little annoying. Even though my current setup still uses octopress, I am editing this markdown using Ghost. One disadvantage of ghost is that it stores all the my blog posts in a local sqlite db, where as in octopress, I can see my markdown files and edit and commit changes to the main repository.</p>

<h2>3 Steps</h2>

<ul>
<li>Setup Ghost Blog</li>
<li>Generate Static Content using <a href="https://github.com/axitkhurana/buster">Buster</a></li>
<li>Gotchas.</li>
</ul>


<h3>Setting up Ghost</h3>

<ul>
<li>Download ghost from <a href="https://ghost.org/download/">here.</a></li>
<li>Install npm dependencies.</li>
<li>npm start to run it on your local machine port 2368.</li>
<li>Click <a href="http://localhost:2368/ghost">here</a> to register a new user and start posting new blog posts.</li>
<li>If you want, you can download additional themes into /content/themes folder and change the theme in your <a href="http://localhost:2368/ghost/settings">ghost settings.</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; npm install
</span><span class='line'>&gt; npm start</span></code></pre></td></tr></table></div></figure>


<h3>Generating Static Pages from your ghost blog using <a href="https://github.com/axitkhurana/buster">Buster.</a></h3>

<ul>
<li>You need wget for buster python package to work.</li>
<li>Download and install wget and its dependencies from <a href="http://gnuwin32.sourceforge.net/packages/wget.htm">here.</a></li>
<li>Install <em>libintl-2</em>, <em>libiconv-2</em>, <em>openssl</em> along with <em>wget</em> as given in the end of the wget download page.</li>
<li>You can install <strong>buster</strong> using pip, and can use <em>buster</em> directly from the command line, but you are likely to face problems if you are using Windows. Instead you can just clone the buster repo and use the <strong>buster.py</strong> directly.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; pip install buster
</span><span class='line'>&gt; buster setup --gh-repo=&lt;repo-url&gt;
</span><span class='line'>&gt; buster generate --domain=http://localhost:2368</span></code></pre></td></tr></table></div></figure>


<h4>or</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; git clone http://github.com/axitkhurana/buster
</span><span class='line'>&gt; cd buster
</span><span class='line'>&gt; python buster/buster.py setup --gh-repo=&lt;repo-url&gt;
</span><span class='line'>&gt; python buster/buster.py generate --domain=http://localhost:2386</span></code></pre></td></tr></table></div></figure>


<ul>
<li><strong><em>setup</em></strong> argumet will ask you for the github repo of your userpage and creates a directory named <strong>static</strong></li>
<li><strong><em>generate</em></strong> argument will recursively download all the static files of a given url into <strong>static</strong> folder.</li>
<li><strong><em>preview</em></strong> argument will start a simple python webserver and hosts the static files in your <strong>static</strong> folder on your localmachine port 9000, so that you can preview the static files genereated by your previous command.</li>
<li><strong><em>deploy</em></strong> will push changes to your github repository</li>
</ul>


<h3>Gotchas</h3>

<ul>
<li><strong>wget</strong> has some problems downloading a webpage using <strong>generate</strong> command because of \\ slashes so remove those according to this <a href="https://github.com/syllogismos/buster/commit/ba2c8df24b78361699e767891f14ed63d775ec21#diff-a61cc6042865036a60870334dd92047cL39">commit.</a></li>
<li>When previewing the static site generated, <strong>.css</strong> and <strong>.js</strong> using pythons SimpleHttpServer, the MIME type is changed to <strong>application/octet-stream</strong>. In order to fix this we have an additional class named <strong>ExtHandler</strong> that extends <em>SimpleHttpRequestHandler</em> to change the default <em>get_type()</em> behaviour.</li>
<li>This <a href="https://github.com/syllogismos/buster/commit/ba2c8df24b78361699e767891f14ed63d775ec21#diff-a61cc6042865036a60870334dd92047cL39">commit</a> has both of the above changes.</li>
<li>If you are on windows, I recommend cloning <a href="http://github.com/syllogismos/buster">this fork</a> of buster instead of the original, that has both of the above fixes.</li>
<li>Some static files aren&rsquo;t downloaded using the <strong>generate</strong> command, my understanding is that the static files that are requested from javascript or fonts requested using css aren&rsquo;t generated. You are better of copying the static files and images that aren&rsquo;t in your static folder directly.</li>
</ul>


<h3>Summary</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## download ghost
</span><span class='line'>&gt; cd ghost
</span><span class='line'>&gt; npm install
</span><span class='line'>&gt; npm start
</span><span class='line'>## ghost blog is in http://localhost:2368
</span><span class='line'>## admin/settings in http://localhost:2368/ghost
</span><span class='line'>
</span><span class='line'>## change to another directory where you want your generated static website to reside
</span><span class='line'>&gt; git clone https://github.com/syllogismos/buster
</span><span class='line'>&gt; cd buster
</span><span class='line'>
</span><span class='line'>&gt; python buster/buster.py setup
</span><span class='line'>## give your github page repository, it creates a static dir
</span><span class='line'>
</span><span class='line'>&gt; python buster/buster.py generate --domain=http://localhost:2368
</span><span class='line'>## downloads all the static files into your static dir
</span><span class='line'>
</span><span class='line'>&gt; python buster/buster.py preview
</span><span class='line'>## to see your downloaded static files are proper
</span><span class='line'>## If you see any of the static files missing, say fonts or images, just copy them from your ghost directory
</span><span class='line'>## make sure your generated static files look okay
</span><span class='line'>
</span><span class='line'>&gt; python buster/buster.py deploy # to commit your changes to the github repo</span></code></pre></td></tr></table></div></figure>


<p>Thank you.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/13/stochastic-gradient-descent/">Stochastic Gradient Descent in AD.</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-09-13T19:17:43+05:30'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>7:17 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In <strong>stochastic gradient descent</strong>, the true gradient is approximated by gradient at each single example.</p>

<p><img src="http://upload.wikimedia.org/math/7/d/9/7d9f6671a202d94d26730ef898d8d4f2.png" alt="update rule" /></p>

<p>As the algorithm sweeps through the training set, it performs the above update for each training example. Several passes can be made over the training set until the algorithm converges, if this is done, the data can be shuffled for each pass to prevent cycles.</p>

<p>Obviously it is faster than normal gradient descent, cause we don&rsquo;t have to compute  cost function over the entire data set in each iteration in case of stochastic gradinet descent.</p>

<h2>stochasticGradientDescent in AD:</h2>

<p>This is my implementation of Stochastic Gradient Descent in AD library, you can get it from <a href="http://github.com/syllogismos/ad">my fork</a> of AD.</p>

<p>Its type signature is</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>stochasticGradientDescent :: (Traversable f, Fractional a, Ord a) 
</span><span class='line'>  =&gt; (forall s. Reifies s Tape =&gt; f (Scalar a) -&gt; f (Reverse s a) -&gt; Reverse s a) 
</span><span class='line'>  -&gt; [f (Scalar a)]
</span><span class='line'>  -&gt; f a 
</span><span class='line'>  -&gt; [f a]</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4>Its arguments are:</h4>

<ul>
<li><code>errorSingle :: (forall s. Reifies s Tape =&gt; f (Scalar a) -&gt; f (Reverse s a) -&gt; Reverse s a)</code> function, that computes error in a single training sample given <code>theta</code></li>
<li>Entire training data, you should be able to map the above <code>errorSingle</code> function over the training data.</li>
<li>and initial Theta</li>
</ul>


<h2>Example:</h2>

<p><a href="https://raw.githubusercontent.com/syllogismos/machine-learning-haskell/master/exampledata.txt">Here</a> is the sample data I&rsquo;m running <code>stochasticGradientDescent</code> on.</p>

<p>Its just 97 rows of samples with two columns, first column is <code>y</code> and the other is <code>x</code></p>

<p>Below is our error function, a simple squared loss error function. You can introduce regularization here if you want.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>errorSingle :: 
</span><span class='line'>  forall a. (Floating a, Mode a) 
</span><span class='line'>  =&gt; [Scalar a] 
</span><span class='line'>  -&gt; [a] 
</span><span class='line'>  -&gt; a
</span><span class='line'>errorSingle d0 theta = sqhalf $ costSingle (tail d0) theta - auto ( head d0)
</span><span class='line'>  where
</span><span class='line'>    sqhalf t = (t**2)/2
</span><span class='line'>    
</span><span class='line'>costSingle x' theta' = constant + sum (zipWith (*) coeff autox')
</span><span class='line'>      where
</span><span class='line'>        constant = head theta'
</span><span class='line'>        autox' = map auto x'
</span><span class='line'>        coeff = tail theta'</span></code></pre></td></tr></table></div></figure>


<p>Running Stochastic Gradient Descent:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>lambda: a &lt;- readFile "exampledata.txt"
</span><span class='line'>lambda: let d = lines a
</span><span class='line'>lambda: let train = map ((read :: String -&gt; [Float]) . (\tmp -&gt; "[" ++ tmp ++ "]")) d
</span><span class='line'>lambda: let sgdRegressor = stochasticGradientDescent errorSingle train
</span><span class='line'>
</span><span class='line'>lambda: sgdRegressor [0, 0] !! 96
</span><span class='line'>[0.2981517,1.2027082]
</span><span class='line'>(0.03 secs, 4228764 bytes)
</span><span class='line'>
</span><span class='line'>lambda: sgdRegressor [0, 0] !! (97*2 -1)
</span><span class='line'>[0.49144596,1.1814859]
</span><span class='line'>(0.03 secs, 2097796 bytes)
</span><span class='line'>
</span><span class='line'>lambda: sgdRegressor [0, 0] !! (97*3 -1)
</span><span class='line'>[0.67614514,1.1605322]
</span><span class='line'>(0.03 secs, 2647504 bytes)
</span><span class='line'>
</span><span class='line'>lambda: sgdRegressor [0, 0] !! (97*4 -1)
</span><span class='line'>[0.8526818,1.1405041]
</span><span class='line'>(0.03 secs, 3158452 bytes)
</span><span class='line'>
</span><span class='line'>lambda: sgdRegressor [0, 0] !! (97*5 -1)
</span><span class='line'>[1.0214167,1.1213613]
</span><span class='line'>(0.05 secs, 3707068 bytes)</span></code></pre></td></tr></table></div></figure>


<h2>Cross checking with <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html">SGDRegressor</a> from scikit-learn</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; import csv
</span><span class='line'>&gt; import numpy as np
</span><span class='line'>&gt; from sklearn import linear_model
</span><span class='line'>
</span><span class='line'>&gt; f = open('exampledata.txt', 'r')
</span><span class='line'>&gt; fcsv = csv.reader(f)
</span><span class='line'>
</span><span class='line'>&gt; d = []
</span><span class='line'>&gt; try:
</span><span class='line'>&gt;    while True:
</span><span class='line'>&gt;        d.append(fcsv.next())
</span><span class='line'>&gt; except:
</span><span class='line'>&gt;     pass
</span><span class='line'>&gt; f.close()
</span><span class='line'>
</span><span class='line'>&gt; for i in range(len(d)):
</span><span class='line'>&gt;     for j in range(2):
</span><span class='line'>&gt;         d[i][j] = float(d[i][j])
</span><span class='line'>
</span><span class='line'>&gt; x = []
</span><span class='line'>&gt; y = []
</span><span class='line'>&gt; for i in range(len(d)):
</span><span class='line'>&gt;     x.append(d[i][1:])
</span><span class='line'>&gt;     y.append(d[i][0])
</span><span class='line'>
</span><span class='line'># initial learning rate eta0 = 0.001
</span><span class='line'># learning rate is constant
</span><span class='line'># regularization parameter alpha = 0.0, as we ignored reqularization
</span><span class='line'># loss function = squared_loss
</span><span class='line'># n_iter or epoch, how many times does the algorithm pass our training data.
</span><span class='line'>&gt; reg = linear_model.SGDRegressor(alpha=0.0, eta0=0.001, loss='squared_loss',n_iter=1, learning_rate='constant' )
</span><span class='line'># start training with initial theta of 0, 0
</span><span class='line'>&gt; sgd = reg.fit(x,y, coef_init=[0], intercept_init=[0])
</span><span class='line'>&gt; print [sgd.intercept_, sgd.coef_]
</span><span class='line'>[array([ 0.29815173]), array([ 1.20270826])]</span></code></pre></td></tr></table></div></figure>


<p>The only restriction we have in our implementation of stochasticGradientDescent is that we set the learning rate a default value of 0.001 and is a constant through out the algorithm.</p>

<p>The rest of the things like the sort of regulariztion, regularization parameter, loss function we are using, we can specify in <code>errorSingle</code>.</p>

<h2>Results:</h2>

<p>So when <code>n_iter = 1</code>, went through the entire data set once, so we must check <code>97th</code> theta from our regression result from <strong>AD</strong>.
Similarly <code>n_iter = 2</code> implies <code>97*2</code> iteration in our implementation, and etc.,</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>n-iter = 1, i = 96
</span><span class='line'>scikit-learn: [array([ 0.29815173]), array([ 1.20270826])]
</span><span class='line'>AD: [0.2981517,1.2027082]
</span><span class='line'>
</span><span class='line'>n-iter = 2, i = 97x2 - 1
</span><span class='line'>scikit-learn: [array([ 0.49144583]), array([ 1.18148583])]  
</span><span class='line'>AD: [0.49144596,1.1814859]
</span><span class='line'>
</span><span class='line'>n-iter = 3, i = 97x3 - 1  
</span><span class='line'>scikit-learn: [array([ 0.67614512]), array([ 1.16053217])]  
</span><span class='line'>AD: [0.67614514,1.1605322]
</span><span class='line'>
</span><span class='line'>n-iter = 4, i = 97x4 - 1  
</span><span class='line'>scikit-learn: [array([ 0.85268182]), array([ 1.14050415])]  
</span><span class='line'>AD: [0.8526818,1.1405041]
</span><span class='line'>
</span><span class='line'>n-iter = 5, i = 97X5 -1  
</span><span class='line'>scikit-learn: [array([ 1.02141669]), array([ 1.12136124])]  
</span><span class='line'>AD: [1.0214167,1.1213613]</span></code></pre></td></tr></table></div></figure>


<p><a href="http://www.github.com/syllogismos/machine-learning-haskell">Here</a> in this repository, you can find the ipython notebook and haskell code so that you can test these yourself.</p>

<h2>References:</h2>

<ol>
<li><a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent on wikipedia</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html">SGDRegressor from scikit-learn</a></li>
<li><a href="http://www.quora.com/Whats-the-difference-between-gradient-descent-and-stochastic-gradient-descent">Gradient Descent vs Stochastic Gradient Descent</a></li>
<li><a href="http://metaoptimize.com/qa/questions/10046/batch-gradient-descent-vs-stochastic-gradient-descent">Batch Gradient Descent vs Stochastic Gradient Descent</a></li>
<li><a href="http://stats.stackexchange.com/questions/49528/batch-gradient-descent-versus-stochastic-gradient-descent">Batch Gradient Descent vs Stochastic Gradient Descent</a></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/04/tinder-like-android-app-that-showcases-products-from-a-fashion-website/">Tinder Like Android App That Showcases Products From a Fashion Website</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-09-04T08:07:44+05:30'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>4</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>8:07 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li>Github repo: <a href="https://github.com/syllogismos/MyntraTinder">https://github.com/syllogismos/MyntraTinder</a></li>
<li>Android app that implements tinder ui, based on <a href="https://github.com/exctasy2/tinder-card-stack">https://github.com/exctasy2/tinder-card-stack</a></li>
<li>Latest apk build file <a href="https://github.com/syllogismos/MyntraTinder/blob/master/app-debug.apk">here</a></li>
<li>Current build is pretty decent, I&rsquo;m pretty happy with it logically, UI can be improved.</li>
</ul>


<h2>UI</h2>

<p><img src="http://i.imgur.com/d7o9Ccz.png" title="Navigation Drawer" alt="Navigation Drawer" />
<img src="http://i.imgur.com/FbgLOf4.png" title="Like" alt="Swipe Right" />
<img src="http://i.imgur.com/sTMeDDr.png" title="Dislike" alt="Swipe Left" /></p>

<h2>Relavent Activities, Fragments, Views, Models, Resources, Layouts and Adapters</h2>

<h3>Activities:</h3>

<ul>
<li><p><strong>MyntraTinderActivity</strong>: This is the main activity that is based on the default DrawerLayoutActivity provided
to us in Android Studio.<br/>
It extends <strong>NavigationDrawerCallbacks</strong> from <strong>NavigationDrawerFragmentSingleElv</strong> to handle click events
in the drawer fragment.</p>

<ul>
<li><em>Layout</em>: <em>activity_myntra_tinder.xml</em></li>
</ul>
</li>
</ul>


<p>The rest of the activities in the project are just for testing and trying various things.</p>

<h3>Fragments:</h3>

<ul>
<li><p><strong>NavigationDrawerFragmentSingleElv</strong>: Fragment that implements the navigation drawer, that has a single
<em>ExpandbleListView</em> where you can find all the product groups, you click on the relavent product group
to get products presented to you in the form a Tinder Stack. It also has a list view for things like
&ldquo;Home&rdquo;, &ldquo;Settings&rdquo; etc.,</p>

<ul>
<li><em>Layouts</em>: <em>fragment_navigation_drawer_myntra_tinder_activity_single_elv.xml</em></li>
<li><em>Adapters</em>: <strong>MyntraCategoryExpandableListAdapter</strong>, to populate various product categories to our <em>ExpandableListView</em></li>
</ul>
</li>
<li><p><strong>TinderUIFragment</strong>: Fragment that has the ProductStackView with in which we showcase a given list of products
in a tinder stack.</p>

<ul>
<li><em>Layouts</em>: <em>fragment_tinder_ui.xml</em></li>
<li><em>Adapters</em>:</li>
</ul>
</li>
<li><p><strong>HomeFragment</strong>: Place holder fragment that you can further develop upon to show what ever you want, currently,
this fragment shows up when you click ListView items like &ldquo;Home&rdquo;, &ldquo;Settings&rdquo;.</p>

<ul>
<li><em>Layouts</em>: <em>fragment_home.xml</em></li>
<li><em>Adapters</em>:</li>
</ul>
</li>
<li><p><strong>LikedProductsFragment</strong>: Fragment that contains a single ListView that is used to display all the liked products from
a single product group. This is implemented inside the <strong>MyntraTinderActivity</strong></p>

<ul>
<li><em>Layouts</em>: <em>activity_product_list_view.xml</em></li>
<li><em>Adapters</em>: <strong>ProductListAdapterWithACursor</strong>, a cursor adapter that takes a cursor obtained from a database
operation and fills our listView</li>
</ul>
</li>
</ul>


<h3>Views:</h3>

<ul>
<li><p><strong>SingleProductView</strong>: View that implements what each Card in the TinderStack looks like, this is what you swipe right
or left to like or dislike a particular product.</p>

<ul>
<li><em>Layouts</em>: <em>product_card.xml</em></li>
<li><em>Adapters</em>:</li>
</ul>
</li>
<li><p><strong>ProductStackView</strong>: View that contains the whole stack,</p>

<ul>
<li><em>Layouts</em>:</li>
<li><em>Adapters</em>: <strong>ProductCardAdapter</strong>, adapter that loads, given list of products in to our tinder stack, you can find
helper functions inside this adapter and see how we initialize the adapter in various cases.</li>
</ul>
</li>
</ul>


<h3>Models:</h3>

<ul>
<li><strong>Product</strong>: A model that defines a single Product and its parameters</li>
<li><strong>MyntraCategory</strong>: A model that defines product categories, sub categories etc., and also an helper function to load
these into our ExpandableListView.</li>
</ul>


<h3>Utils:</h3>

<ul>
<li><strong>DatabaseHelper</strong>: Helper functions that handle all database operations and our db schema is also defined in this.</li>
<li><strong>Downloader</strong>: Helper functions to download json, to our phones filesystem, given url, postData and filename</li>
<li><strong>ProductsJSONPullParser</strong>: Helper functions to parse a given json file and return a list of Products.</li>
</ul>


<h2>Additional Notes:</h2>

<h4>Note1:</h4>

<p>When you select a product category/group in the expandable list view, it queries the database for 20 products from that
category, if the db doesn&rsquo;t even have a single product from that category, it gets new products from the server side, 96
at a time and fill the db with new products. And returns 20 new products to the ProductStackAdapter</p>

<h4>Note2:</h4>

<p>Our product categories have 3 levels of hierarchy, but ExpandableListView has only 2 levels, so the top most level,
say &ldquo;Men&rdquo; is also technically a &ldquo;Group&rdquo; with no children, it only behaves as a header to the next two levels in the hierarchy.
Below is the actual hierarchy of product groups.</p>

<ul>
<li>Men

<ul>
<li>Footwear

<ol>
<li>Casual Shoes</li>
<li>Formal Shoes</li>
</ol>
</li>
<li>Accessories

<ol>
<li>Watches</li>
<li>Sunglasses</li>
</ol>
</li>
</ul>
</li>
<li>Women

<ul>
<li>Footwear

<ol>
<li>Heels</li>
<li>Wedges</li>
</ol>
</li>
<li>Accessories

<ol>
<li>Watches</li>
<li>Sunglasses</li>
</ol>
</li>
</ul>
</li>
</ul>


<p>But for our convenience, to put it inside an ExpandableListView, we changed it to below</p>

<ul>
<li>Men</li>
<li>Footwear

<ol>
<li>Casual Shoes</li>
<li>Formal Shoes</li>
</ol>
</li>
<li>Accessories

<ol>
<li>Watches</li>
<li>Sunglasses</li>
</ol>
</li>
<li>Women</li>
<li>Footwear

<ol>
<li>Heels</li>
<li>Wedges</li>
</ol>
</li>
<li>Accessories

<ol>
<li>Watches</li>
<li>Sunglasses</li>
</ol>
</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/26/a-boilerplate-nodejs-twitter-bot-that-responds-to-twitter-mentions/">A Boilerplate Nodejs Twitter Bot That Responds to Twitter Mentions.</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-08-26T23:20:56+05:30'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>11:20 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Start by forking this <a href="https://github.com/syllogismos/twitter-bot-template">github repo</a></p>

<h2>Config:</h2>

<p>Make a copy of config.template.json named config.json, and fill your secret keys of your twitter bot that you obtain from <a href="https://apps.twitter.com">here</a> and make sure your twitter app has both read and write access in the &ldquo;permissions&rdquo; tab.</p>

<h2>Installation</h2>

<p>Install all the node dependencies.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; npm install</span></code></pre></td></tr></table></div></figure>


<h2>Your bot code.</h2>

<p>The bot is written in coffeescript, and the compiled javascript is also provided in case if you prefer that.</p>

<p>At the least you need to fill the function <strong>solve</strong> whose only argument is the tweet text, include all the mentions. Not the Tweet Object, its just the tweet text.</p>

<p>You are also provided with a function <strong>isOfWrongFormat</strong> that defaults to <em>false</em> which checks the validity of the tweet text. And its only argument is the tweet text as well. Not the tweet object.</p>

<h2>Running the bot.</h2>

<p>If you wrote the bot in coffee-script do this</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; coffee twitterBot.coffee</span></code></pre></td></tr></table></div></figure>


<p>Or if you wrote it in plain javascript do this</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; node twitterBot.js</span></code></pre></td></tr></table></div></figure>


<p>If you want to compile your coffee-script to plain javascript you can run the coffee command with a <em>-c</em> flag</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; coffee -c twitterBot.coffee</span></code></pre></td></tr></table></div></figure>


<h2>Sample Bot</h2>

<p>You can find a sample twitter bot that I wrote based on this, albeit slightly modified is <a href="https://github.com/syllogismos/countdownbot">countdownbot</a></p>

<p>It responds with a solution of the <strong>numbers game</strong> from the game show <strong>Countdown</strong>, if someone mentions the bot along with the target number and the rest of the numbers..</p>

<p>After you fill the config in the countdownbot as shown above, and ran it, Anyone mentioning your bot along with a set of numbers, with the first one being the target number</p>

<p>@someRandomPerson: @countdownbot 347 2 3 10 75 23 12</p>

<p>it responds like this.</p>

<p>@countdownbot: @someRandomPerson One possible solution for 347 is: (10*(12+23))-3</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/10/octopress-blog-as-user-page-in-github/">Octopress Blog as User Page in Github, Using Windows</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-08-10T16:15:42+05:30'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>4:15 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Step by step instructions to install Octopress blog on Windows to setup your github use page.</p>

<ul>
<li>Download RubyInstaller and ruby dev kit from <a href="http://dl.bintray.com/oneclick/rubyinstaller/rubyinstaller-1.9.3-p545.exe?direct">here</a> and <a href="https://github.com/downloads/oneclick/rubyinstaller/DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe">here</a></li>
<li>The above installer installs Ruby 1.9.3, eventhough the most recent stable version > 2.0.0</li>
<li>Go to the directory where the dev-kit is installed and do the following</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cd ruby-dev-kit
</span><span class='line'>&gt; ruby dk.rb init
</span><span class='line'>&gt; ruby dk.rb install</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Setup Octopress, change to the directory where you want your blog to reside</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; git clone git://github.com/imathis/octopress.git octopress
</span><span class='line'>&gt; cd octopress</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Install dependencies</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; gem install bundler
</span><span class='line'>&gt; bundle install</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Install default Octopress theme.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; rake install</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Configure your blog by updating _config.yml, name of your blog, your name and things like that.</li>
<li>Create a new repo of the form YOUR-GITHUB-USER-NAME.github.io in github</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; rake setup_github_pages
</span><span class='line'># this command will ask your for your github pages url, so type 
</span><span class='line'>https://github.com/YOUR-GITHUB-USER-NAME/YOUR-GITHUB-USER-NAME.github.io</span></code></pre></td></tr></table></div></figure>


<ul>
<li>and run the following commands to deploy your local blog to github</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; rake generate
</span><span class='line'>&gt; rake deploy
</span><span class='line'># what this does is basically makes the master branch of your github repo contain all the generated
</span><span class='line'># files namely _deploy folder in your directory.</span></code></pre></td></tr></table></div></figure>


<ul>
<li>If everything worked fine, you will be able to see your blog with the defalt octopress template on YOUR-GITHUB-USER-NAME.github.io</li>
<li>Every time you update your blog you need ro do <em>rake generate</em> and <em>rake deploy</em> these commands will push your changes to your master branch on the remote</li>
<li>You can make a new post using <em>rake new_post</em> command</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; rake new_post["My first Blog Post"]</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The above command creates a new markdown file in source/_posts folder, write your blog in markdown</li>
<li>Commit the changes you made locally in your local branch <em>source</em></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; git status
</span><span class='line'># this will show that there are changes in the folder source/_posts
</span><span class='line'>&gt; git add .
</span><span class='line'>&gt; git commit -m "my first blog post"</span></code></pre></td></tr></table></div></figure>


<ul>
<li>If you want can create a new branch called <em>source</em> in your remote repository for the source files</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; git push origin source</span></code></pre></td></tr></table></div></figure>


<h2>This is what you do everytime you create a new post</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; rake new_post["new blog post"]
</span><span class='line'>&gt; rake generate
</span><span class='line'>&gt; rake deploy # to deploy static files in the remote master branch.
</span><span class='line'>&gt; git add . # or you can specify the markdown file
</span><span class='line'>&gt; git commit -m "new blog post"
</span><span class='line'>&gt; git push origin source # to push the source files to the source branch</span></code></pre></td></tr></table></div></figure>


<p>I only did this because my newly minted blog doesn&rsquo;t contain many entries :D</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/10/facebook-link-prediction/">Facebook Link Prediction</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-08-10T08:11:37+05:30'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>8:11 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>note: I did this just as an exercise, you get much more from <a href="http://blog.echen.me/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/">this post</a>.</p>

<h2>Link Prediction:</h2>

<p>We are given snapshot of a network and would like to infer which which interactions among existing
members are likely to occur in the near future or which existing interactions are we missing. The challenge is to effectively combine the information from the network structure with rich node and edge
attribute data.</p>

<h2>Supervised Random Walks:</h2>

<p>This repository is the implementation of Link prediction based on the paper Supervised Random Walks by  Lars Backstrom et al. The essence of which is that we combine the information from the network structure with the node and edge level attributes using Supervised Random Walks. We achieve this by using these attributes to guide a random walk on the graph. We formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. We develop an efficient training algorithm to directly learn the edge strength estimation function.</p>

<h2>Problem Description:</h2>

<p>We are given a directed graph <em>G(V,E)</em>, a node <em>s</em> and a set of candidates to which <em>s</em> could create an edge. We label nodes to which <em>s</em> creates edges in the future as <em>destination nodes D = {d<sub>1</sub>,..,d<sub>k</sub>}</em>, while we call the other nodes to which s does not create edges no-link nodes <em>L = {l<sub>1</sub>,..,l<sub>n</sub>}</em>. We label candidate nodes with a set <em>C = D union L</em>. <em>D</em> are positive training examples and <em>L</em> are negative training examples. We can generalize this to multiple instances of <em>s, D, L</em>. Each node and each edge in G is further described with a set of features. We assume that each edge <em>(u,v)</em> has a corresponding feature vector psi<sub>uv</sub> that describes u and v and the interaction attributes.</p>

<p>For each edge (u,v) in G we compute the strength <em>a<sub>uv</sub> = f<sub>w</sub>(psi<sub>uv</sub>)</em>. Function <em>f<sub>w</sub></em> parameterized by <em>w</em> takes the edge feature vector <em>psi<sub>uv</sub></em> as input and computes the corresponding edge strength <em>a<sub>uv</sub></em> that models the random walk transition probability. It is exactly the function <em>f<sub>w</sub>(psi)</em> we learn in the training phase of the algorithm.</p>

<p>To predict new edges to <em>s</em>, first edge strengths of all edges are calculated using <em>f<sub>w</sub></em>. Then random walk with restarts is run from <em>s</em>. The stationary distribution <em>p</em> of random walk assigns each node <em>u</em> a probability <em>p<sub>u</sub></em>. Nodes are ordered by <em>p<sub>u</sub></em> and top ranked nodes are predicted as future destination nodes to <em>s</em>. The task is to learn the parameters <em>w</em> of function <em>f<sub>w</sub>(psi<sub>uv</sub>)</em> that assigns each edge a transition probability. One can think of the weights <em>a<sub>uv</sub></em> as edge strengths and the random walk is more likely to traverse edges of high strength and thus nodes connected to node <em>s</em> via paths of strong edges will likely to be visited by the random walk and will thus rank higher.</p>

<h3>The optimization problem:</h3>

<p>The training data contains information that source node <em>s</em> will create edges to node <em>d subset D</em> and not <em>l subset L</em>. So we set parameters <em>w</em> of the function <em>f<sub>w</sub>(psi<sub>uv</sub>)</em> so that it will assign edge weights <em>a<sub>uv</sub></em> in such a way that the random walk will be more likely to visit nodes in <em>D</em> than <em>L</em>, <em>i.e.,</em> <em>p<sub>l</sub> &lt; p<sub>d</sub></em> for each <em>d subset D</em> and <em>l subset L</em>. And thus we define the optimization problem as follows.<br/>
<img src="http://i.imgur.com/zMjJ1Nb.png" alt="optimization problem hard version" /></p>

<p>where <em>p</em> is the vector of pagerank scores. Pagerank scores <em>p<sub>i</sub></em> depend on edge strength on <em>a<sub>uv</sub></em> and thus actually depend on <em>f<sub>w</sub>(psi<sub>uv</sub>)</em> which is parameterized by <em>w</em>. The above equation (1) simply states that we want to find <em>w</em> such that the pagerank score of nodes in <em>D</em> will be greater than the scores of nodes in <em>L</em>. We prefer the shortest <em>w</em> parameters simply for the sake of regularization. But the above equation is the &ldquo;hard&rdquo; version of the optimization problem. However it is unlikely that a solution satisfying all the constraints exist. We make the optimization problem &ldquo;soft&rdquo; by introducing a loss function that penalizes the violated constraints. Now the optimization problem becomes,<br/>
<img src="http://i.imgur.com/oZ2pYN1.png" alt="optimization problem soft version." /><br/>
where lambda is the regularization parameter that trades off between the complexity(norm of <em>w</em>) for the fit of the model(how much the constraints can be violated). And <em>h(.)</em> is a loss function that assigns a non-negative penalty according to the difference of the scores <em>p<sub>l</sub>-p<sub>d</sub></em>. <em>h(.) = 0</em> if <em>p<sub>l</sub> &lt; p<sub>d</sub></em> as the constraint is not violated and <em>h(.) > 0</em> if <em>p<sub>l</sub> > p<sub>d</sub></em></p>

<h3>Solving the optimization problem:</h3>

<p>First we need to establish connection between the parameters <em>w</em> and the random walk scores <em>p</em>. Then we show how to obtain partial derivatives of the loss function and <em>p</em> with respect to <em>w</em> and then perform gradient descent to obtain optimal values of <em>w</em> and minimize loss.
We build a random walk stochastic transition matrix <em>Q<sup>&lsquo;</sup></em> from the edge strengths <em>a<sub>uv</sub></em> calculated from <em>f<sub>w</sub>(psi<sub>uv</sub>)</em>.<br/>
<img src="http://i.imgur.com/JiSHf7t.png" alt="Q dash" /></p>

<p>To obtain the final random walk transition probability matrix <em>Q</em>, we also incorporate the restart probability <em>alpha</em>, <em>i.e.,</em> the probability with which the random walk jumps back to seed node <em>s</em>, and thus &ldquo;restarts&rdquo;.<br/>
<img src="http://i.imgur.com/vE2P7LJ.png" alt="Q" /></p>

<p>each entry <em>Q<sub>uv</sub></em> deﬁnes the conditional probability that a walk will traverse edge (u, v) given that it is currently at node u.
The vector <em>p</em> is the stationary distribution of the Random Walk with restarts(also known as Personalized Page Rank), and is the solution to the following eigen vector equation.<br/>
<img src="http://i.imgur.com/UFwnobA.png" alt="eigen vector equation" /></p>

<p>The above equation establishes the connection between page rank scores <em>p</em> and the parameters <em>w</em> via the random walk transition probability matrix <em>Q</em>. Our goal now is to minimize the soft version of the loss function(eq. 2) with respect to parameter vector <em>w</em>. We do this by obtaining the gradient of <em>F(w)</em> with respect to <em>w</em>, and then performing gradient based optimization method to find <em>w</em> that minimize <em>F(w)</em>. This gets complicated due to the fact that equation 4 is recursive. For this we introduce <em>delta<sub>ld</sub> = p<sub>l</sub>-p<sub>d</sub></em> and then we can write the derivative<br/>
<img src="http://i.imgur.com/FhZVZEB.png" alt="delta ld" /><br/>
and then we can write the derivative of <em>F(w)</em> as follows<br/>
<img src="http://i.imgur.com/oisE40X.png" alt="lossfunction gradient with delta" /><br/>
For commonly used loss functions <em>h(.)</em> it is easy to calculate derivative, but it is not clear how to obtain partial derivatives of <em>p</em> wrt <em>w</em>. <em>p</em> is the principle eigen vector of matrix <em>Q</em>. The above eigen vector equation can also be written as follows.<br/>
<img src="http://i.imgur.com/z00CXm4.png" alt="eigen vector reduced form." /><br/>
and taking the derivatives now gives<br/>
<img src="http://i.imgur.com/FhZVZEB.png" alt="derivative of p recursive form" /><br/>
above <em>p<sub>u</sub></em> and its partial derivative are entangled in the equation, however we compute the above values iteratively as follows<br/>
<img src="http://i.imgur.com/WneoOOn.png" alt="power method to compute p and its partial derivative iteratively." /><br/>
we initialize the vector <em>p</em> as <em>1/|V|</em> and all its derivatives as zeroes before the iteration starts and terminates the recursion till the <em>p</em> and its derivatives converge for an epsilon say <em>10e-12</em>.
To solve equation 4, we need partial derivative of <em>Q<sub>ju</sub></em>, this calculation is straight forward. When <em>(j,u) subset E</em> derivative of <em>Q<sub>ju</sub></em> is<br/>
<img src="http://i.imgur.com/aLDlWP4.png" alt="partial derivative of Qju" /><br/>
and derivative of <em>Q<sub>ju</sub></em> is zero if edge <em>(j,u)</em> is not a subset of <em>E</em>.</p>

<h2>My Implementation:</h2>

<p>We are given a huge network with existing connections. When predicting future link of a particular node, we consider that <em>s</em>, and the graph <em>G(E,V)</em> is
Here we explain how each helper function and main functions implements the above algorithm..</p>

<h3>FeaturesFromAdjacentMatrix.m:</h3>

<p>This is a temporary function specific to the facebook data that generates Features of each edge from a given adjacency matrix. For other problems this function must be replaced with something that generates feature vector for each edge based on graph <em>G(E,V)</em> and node, edge attributes. For an network with <em>n</em> nodes this function returns <em>n x n x m</em> matrix, where <em>m</em> is the size of parameter vector <em>w</em>(sometimes <em>m+1</em>)</p>

<ul>
<li><p>arguments:</p>

<ul>
<li>Adjacency matrix, node attributes, edge attributes</li>
</ul>
</li>
<li><p>returns:</p>

<ul>
<li><em>psi size(nxnxm)</em></li>
</ul>
</li>
</ul>


<h3>FeaturesToEdgeStrength.m:</h3>

<p>This function takes the feature matrix (<em>psi</em>) and the parameter vector (<em>w</em>) as arguments to return edge strength (<em>A</em>) and partial derivative of edge strength wrt to each parameter(<em>dA</em>). We also compute partial derivative of edge strength to make further calculations easier. We can vary edge strength function in future implementations, in this we used <em>sigmod(w x psi<sub>uv</sub>)</em> as edge strength function.</p>

<ul>
<li><p>arguments:</p>

<ul>
<li><em>psi size(nxnxm)</em></li>
<li><em>w size(1xm)</em></li>
</ul>
</li>
<li><p>returns:</p>

<ul>
<li><em>A size(nxn)</em></li>
<li><em>dA size(nxnxm)</em></li>
</ul>
</li>
</ul>


<h3>EdgeStrengthToTransitionProbability.m</h3>

<p>This function takes the edge strength matrix <em>A</em> and <em>alpha</em> to compute transition probability matrix <em>Q</em>.</p>

<ul>
<li><p>arguments:</p>

<ul>
<li><em>A size(nxn)</em></li>
<li><em>alpha size(1x1)</em></li>
</ul>
</li>
<li><p>returns:</p>

<ul>
<li><em>Q size(nxn)</em></li>
</ul>
</li>
</ul>


<h3>EdgeStrengthToPartialdiffTransition.m</h3>

<p>This function computes partial derivative of transition probability matrix from <em>A</em>, <em>dA</em> and <em>alpha</em></p>

<ul>
<li><p>arguments:</p>

<ul>
<li><em>A size(nxn)</em></li>
<li><em>dA size(nxnxm)</em></li>
<li><em>alpha size(1x1)</em></li>
</ul>
</li>
<li><p>returns:</p>

<ul>
<li><em>dQ size(nxnxm)</em></li>
</ul>
</li>
</ul>


<h3>LossFunction.m</h3>

<p>This function takes as input parameters, adjacency matrix of the network, lambda and alpha.
* We get edge strength matrix and its partial derivatives from features and parameters
* We get transition probability and partial derivatives of it from <em>A</em> and <em>dA</em>
* We get stationary probabilities from <em>Q</em> and <em>dQ</em>
* Compute cost and gradient from the above variables, we can use various functions as loss function <em>h(.)</em>. Here we used wilcoxon loss function.</p>

<ul>
<li><p>arguments:</p>

<ul>
<li>param: parameters of the edge strength function, size(1,m)</li>
<li>features: features of all the edges in the network, size(n,n,m)</li>
<li>d: binary vector representing destination nodes, size(1,n)</li>
<li>lambda: regularization parameter, size(1,1)</li>
<li>alpha: random restart parameter, size(1,1)</li>
</ul>
</li>
<li><p>returns:</p>

<ul>
<li>J: loss, size(1,1)</li>
<li>grad: gradient of cost wrt parameters, size(1,m)</li>
</ul>
</li>
</ul>


<h3>fmincg.m</h3>

<p>We use this function to do the minimization of the loss function, given a starting point for the parameters, and the function that computes loss and gradients for a given parameter vector. This is similar to fminunc function available in octave.</p>

<h3>GetNodesFromParam.m</h3>

<p>This function calculates the closest nodes to the root node given the parameters obtained after training.</p>

<ul>
<li><p>arguments:</p>

<ul>
<li>param: parameters, size(m,1)</li>
<li>features: feature matrix, size(n,n,m)</li>
<li>d: binary vector representing the destination nodes, size(1,n)</li>
<li>alpha: alpha value used in calculation of Q, size(1,1)</li>
<li>y: number of nodes to output</li>
</ul>
</li>
<li><p>returns:</p>

<ul>
<li>nodes: output nodes, size(1,y)</li>
<li>P: probabilities of the nodes, size(1,n)</li>
</ul>
</li>
</ul>


<h2>How to Train:</h2>

<p>Here I will show how to train the supervised random walk for a given root node <em>s</em> and edge features matrix <em>psi</em>.
I&rsquo;m not showing how to obtain the edge features. Given the network structure, node and edge attributes etc, you can experiment with different feature extraction techniques.
Here we have <em>psi</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>octave:1&gt; clear, close all, clc;
</span><span class='line'>octave:2&gt; rand("seed", 3410);
</span><span class='line'>octave:3&gt; m = size(psi)(3);
</span><span class='line'>octave:4&gt; n = size(psi)(1);
</span><span class='line'>octave:5&gt; initial_w = zeroes(1,m);   % initialize the parameters to zeros or rand
</span><span class='line'>octave:6&gt; initial_w = rand(1,n);
</span><span class='line'>
</span><span class='line'>% to calculate the loss for a given parameter vector.
</span><span class='line'>
</span><span class='line'>octave:7&gt; [loss, grad] = LossFunction(initial_w, psi, d, lambda=1, alpha=0.2, b=0.4);
</span><span class='line'>
</span><span class='line'>% d above is a binary vector that represents the destination nodes to begin with, 
</span><span class='line'>% you can initialize this randomly or obtain it from the graph
</span><span class='line'>
</span><span class='line'>% training
</span><span class='line'>octave:8&gt; options = optimset('GradObj', 'on', 'MaxIter', 20);
</span><span class='line'>octave:9&gt; [w,loss] = ...
</span><span class='line'>  fmincg(@(t)(LossFunction(t, psi, d, lambda=1,alpha=0.2,b=0.4)),
</span><span class='line'>  initial_w, options);
</span><span class='line'>
</span><span class='line'>% w obtained above is the parameters we obtained after gradient descent
</span><span class='line'>
</span><span class='line'>octave:10&gt; y = 10;
</span><span class='line'>octave:11&gt; [nodes, P] = GetNodesFromParam(w, psi,d,alpha = 0.2,y);</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/10/welcome-to-my-website/">Welcome to My Blog</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-08-10T07:23:56+05:30'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>7:23 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img src="http://i.minus.com/iR5NTkhHOUE41.gif" alt="Rachel Riley" /></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/09/15/ghost-blog-as-your-github-profile-page/">Ghost Blog as Your Github User Page</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/09/13/stochastic-gradient-descent/">Stochastic Gradient Descent in AD.</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/09/04/tinder-like-android-app-that-showcases-products-from-a-fashion-website/">Tinder Like Android App That Showcases Products From a Fashion Website</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/08/26/a-boilerplate-nodejs-twitter-bot-that-responds-to-twitter-mentions/">A Boilerplate Nodejs Twitter Bot That Responds to Twitter Mentions.</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/08/10/octopress-blog-as-user-page-in-github/">Octopress Blog as User Page in Github, Using Windows</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/syllogismos">@syllogismos</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'syllogismos',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - syllogismos -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
